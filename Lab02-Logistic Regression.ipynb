{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNziUKA/Yh6tJccsDqBvbgI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"e4AL5rHNcpkc","executionInfo":{"status":"ok","timestamp":1762703301170,"user_tz":-330,"elapsed":3428,"user":{"displayName":"navas roshan","userId":"12864937970405172599"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Step 1: Load the dataset\n","from sklearn.datasets import load_iris\n","iris = load_iris()\n","\n","\n","X = iris.data\n","X = np.hstack([np.ones((X.shape[0], 1)), X])\n","y = iris.target\n","y = y.reshape(-1, 1)\n","\n","encoder = OneHotEncoder(sparse_output=False)\n","y = encoder.fit_transform(y)\n","\n","# Step 2: Split into train and test\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=43\n",")"]},{"cell_type":"code","source":["Number_Of_Classes = len(y_train[0])\n","Number_Of_Samples = len(X_train)\n","Number_Of_Features = len(X_train[0])\n","\n","W = np.random.rand(Number_Of_Classes, Number_Of_Features)\n","\n","# Learning rate\n","eta = 0.04\n","epochs = 100\n","\n","for epoch in range(epochs):\n","    # Compute scores: shape (N, C)\n","    scores = X_train @ W.T\n","\n","    # Softmax probabilities: shape (N, C)\n","    exp_scores = np.exp(scores - np.max(scores, axis=1, keepdims=True))  # stability\n","    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n","\n","    # Gradient: (C, F)\n","    gradient = (y_train - probs).T @ X_train\n","\n","    # Update weights (gradient ascent)\n","    W += eta * gradient / Number_Of_Samples\n","\n","    # (Optional) compute log-likelihood\n","    if epoch % 10 == 0:\n","        ll = np.sum(y_train * np.log(probs + 1e-9))\n","        print(f\"Epoch {epoch}, JLL: {ll:.4f}\")\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7LyvGLiyoFl8","executionInfo":{"status":"ok","timestamp":1762703301240,"user_tz":-330,"elapsed":22,"user":{"displayName":"navas roshan","userId":"12864937970405172599"}},"outputId":"513d30d7-5399-4686-c4d5-0cd445f0f8d1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, JLL: -271.0307\n","Epoch 10, JLL: -110.9343\n","Epoch 20, JLL: -94.7877\n","Epoch 30, JLL: -84.8135\n","Epoch 40, JLL: -78.1168\n","Epoch 50, JLL: -73.2797\n","Epoch 60, JLL: -69.5781\n","Epoch 70, JLL: -66.6160\n","Epoch 80, JLL: -64.1620\n","Epoch 90, JLL: -62.0727\n"]}]},{"cell_type":"code","source":["y_pred = np.argmax(X_test @ W.T, axis=1)\n","y_true = np.argmax(y_test, axis=1)\n","\n","accuracy = np.mean(y_pred == y_true)\n","print(\"Accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oj63DJLiq4WJ","executionInfo":{"status":"ok","timestamp":1762703301262,"user_tz":-330,"elapsed":18,"user":{"displayName":"navas roshan","userId":"12864937970405172599"}},"outputId":"8c58c21d-a2fd-4ef8-86b4-84e4f0933119"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9666666666666667\n"]}]}]}