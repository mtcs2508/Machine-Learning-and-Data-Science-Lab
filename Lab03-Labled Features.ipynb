{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdACvZ0j4hSu1iTIx1GVyd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GCLOHuq8rZgS"},"outputs":[],"source":["import numpy as np\n","from collections import Counter, defaultdict\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from scipy.special import softmax\n","import random\n","\n","# -------------------------\n","# Toy dataset (unlabeled docs)\n","# -------------------------\n","docs = [\n","    \"The puck went into the goal\",\n","    \"He scored a goal in hockey\",\n","    \"The company profit increased\",\n","    \"New investment boosted profit\",\n","    \"Hockey players use a puck\",\n","    \"Financial analysts predict growth\",\n","]\n","\n","# Classes\n","labels = [\"hockey\", \"finance\"]\n","\n","# -------------------------\n","# Step 1: Feature extraction\n","# -------------------------\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(docs)\n","vocab = vectorizer.get_feature_names_out()\n","N, D = X.shape\n","print(\"Vocabulary:\", vocab)\n","\n","# -------------------------\n","# Step 2: Labeled features (domain knowledge)\n","# -------------------------\n","# Format: feature -> reference distribution over classes\n","# Example: puck strongly => hockey, profit strongly => finance\n","labeled_features = {\n","    \"puck\": np.array([0.95, 0.05]),      # mostly hockey\n","    \"goal\": np.array([0.9, 0.1]),\n","    \"profit\": np.array([0.05, 0.95]),    # mostly finance\n","}\n","\n","# -------------------------\n","# Step 3: GE-FL loss function\n","# -------------------------\n","def ge_loss(weights, X, labeled_features, sigma=1.0):\n","    \"\"\"\n","    GE-FL objective: sum of KL divergences for labeled features\n","    + Gaussian prior on weights\n","    \"\"\"\n","    W = weights.reshape(D, len(labels))  # weight matrix (features x classes)\n","    loss = 0.0\n","\n","    # For each labeled feature, compute model’s predicted distribution\n","    for feat, ref_dist in labeled_features.items():\n","        if feat not in vocab:\n","            continue\n","        j = np.where(vocab == feat)[0][0]  # feature index\n","        mask = X[:, j].toarray().ravel() > 0\n","        if mask.sum() == 0:\n","            continue\n","\n","        # Subset of docs containing the feature\n","        X_feat = X[mask]\n","        scores = X_feat @ W\n","        probs = softmax(scores, axis=1)\n","        avg_pred = probs.mean(axis=0)  # model’s expected distribution\n","\n","        # KL divergence between ref_dist and avg_pred\n","        kl = np.sum(ref_dist * (np.log(ref_dist + 1e-9) - np.log(avg_pred + 1e-9)))\n","        loss += kl\n","\n","    # Gaussian prior on weights\n","    loss += np.sum(W**2) / (2 * sigma**2)\n","    return loss\n","\n","# -------------------------\n","# Step 4: Training with gradient descent\n","# -------------------------\n","def train_gefl(X, labeled_features, vocab, lr=0.5, epochs=200):\n","    W = np.random.randn(X.shape[1], len(labels)) * 0.01\n","\n","    for epoch in range(epochs):\n","        # Simple gradient approximation (finite difference, for clarity)\n","        loss = ge_loss(W, X, labeled_features)\n","        grad = np.zeros_like(W)\n","        eps = 1e-4\n","        for i in range(W.shape[0]):\n","            for j in range(W.shape[1]):\n","                W[i, j] += eps\n","                l2 = ge_loss(W, X, labeled_features)\n","                W[i, j] -= eps\n","                grad[i, j] = (l2 - loss) / eps\n","        W -= lr * grad\n","        if epoch % 50 == 0:\n","            print(f\"Epoch {epoch}, Loss={loss:.4f}\")\n","    return W\n","\n","W = train_gefl(X, labeled_features, vocab)\n","\n","# -------------------------\n","# Step 5: Predictions\n","# -------------------------\n","def predict(doc):\n","    vec = vectorizer.transform([doc])\n","    scores = vec @ W\n","    probs = softmax(scores, axis=1)[0]\n","    return {c: round(p, 3) for c, p in zip(labels, probs)}\n","\n","print(\"\\nPredictions:\")\n","print(\"Doc: 'Hockey match with a puck' =>\", predict(\"Hockey match with a puck\"))\n","print(\"Doc: 'Company profit report' =>\", predict(\"Company profit report\"))"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.feature_extraction.text import CountVectorizer\n","from scipy.special import softmax\n","\n","# -------------------------\n","# Step 1: Load dataset\n","# -------------------------\n","categories = ['rec.sport.hockey', 'sci.electronics']\n","newsgroups = fetch_20newsgroups(\n","    subset='train',\n","    categories=categories,\n","    remove=('headers', 'footers', 'quotes')\n",")\n","docs = newsgroups.data\n","labels = categories\n","print(f\"Loaded {len(docs)} documents from categories: {labels}\")\n","\n","# -------------------------\n","# Step 2: Feature extraction\n","# -------------------------\n","vectorizer = CountVectorizer(max_features=2000, stop_words='english')\n","X = vectorizer.fit_transform(docs)\n","vocab = vectorizer.get_feature_names_out()\n","N, D = X.shape\n","print(\"Vocabulary size:\", D)\n","\n","# -------------------------\n","# Step 3: Labeled features (domain knowledge)\n","# -------------------------\n","labeled_features = {\n","    \"puck\": np.array([0.95, 0.05]),\n","    \"goal\": np.array([0.9, 0.1]),\n","    \"hockey\": np.array([0.95, 0.05]),\n","    \"team\": np.array([0.8, 0.2]),\n","    \"stick\": np.array([0.9, 0.1]),\n","    \"circuit\": np.array([0.1, 0.9]),\n","    \"voltage\": np.array([0.05, 0.95]),\n","    \"chip\": np.array([0.05, 0.95]),\n","    \"board\": np.array([0.2, 0.8]),\n","    \"resistor\": np.array([0.05, 0.95]),\n","}\n","\n","# -------------------------\n","# Step 4: GE-FL loss + gradient\n","# -------------------------\n","def ge_loss_and_grad(W, X, labeled_features, sigma=1.0):\n","    W = W.reshape(D, len(labels))\n","    loss = 0.0\n","    grad = np.zeros_like(W)\n","\n","    for feat, ref_dist in labeled_features.items():\n","        if feat not in vocab:\n","            continue\n","\n","        j = np.where(vocab == feat)[0][0]\n","        mask = X[:, j].toarray().ravel() > 0\n","        if mask.sum() == 0:\n","            continue\n","\n","        X_feat = X[mask].toarray()  # convert to dense to simplify\n","        scores = X_feat @ W  # (num_docs_with_feat, num_classes)\n","        probs = softmax(scores, axis=1)\n","        avg_pred = probs.mean(axis=0)\n","\n","        # KL Divergence (ref || pred)\n","        kl = np.sum(ref_dist * (np.log(ref_dist + 1e-9) - np.log(avg_pred + 1e-9)))\n","        loss += kl\n","\n","        # Gradient (approximation)\n","        diff = (avg_pred - ref_dist)[None, :]  # shape (1, num_classes)\n","        grad_contrib = (X_feat.T @ np.tile(diff, (X_feat.shape[0], 1))) / X_feat.shape[0]\n","        grad += grad_contrib\n","\n","    # Gaussian prior\n","    loss += np.sum(W**2) / (2 * sigma**2)\n","    grad += W / (sigma**2)\n","\n","    return loss, grad\n","\n","# -------------------------\n","# Step 5: Training (gradient descent)\n","# -------------------------\n","def train_gefl(X, labeled_features, lr=0.1, epochs=100):\n","    W = np.random.randn(X.shape[1], len(labels)) * 0.01\n","    for epoch in range(epochs):\n","        loss, grad = ge_loss_and_grad(W, X, labeled_features)\n","        W -= lr * grad\n","        if epoch % 10 == 0:\n","            print(f\"Epoch {epoch}, Loss={loss:.4f}\")\n","    return W\n","\n","W = train_gefl(X, labeled_features, lr=0.1, epochs=100)\n","\n","# -------------------------\n","# Step 6: Prediction\n","# -------------------------\n","def predict(doc):\n","    vec = vectorizer.transform([doc])\n","    scores = vec @ W\n","    probs = softmax(scores, axis=1)[0]\n","    return {c: round(p, 3) for c, p in zip(labels, probs)}\n","\n","# -------------------------\n","# Step 7: Example predictions\n","# -------------------------\n","print(\"\\nPredictions:\")\n","print(\"Doc: 'The hockey puck hit the goal' =>\", predict(\"The hockey puck hit the goal\"))\n","print(\"Doc: 'The voltage in the circuit is high' =>\", predict(\"The voltage in the circuit is high\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyZROcPVY21W","executionInfo":{"status":"ok","timestamp":1762705420622,"user_tz":-330,"elapsed":6341,"user":{"displayName":"navas roshan","userId":"12864937970405172599"}},"outputId":"5b0520ff-fa63-4d66-a9ff-f3a34b5efd72"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 1191 documents from categories: ['rec.sport.hockey', 'sci.electronics']\n","Vocabulary size: 2000\n","Epoch 0, Loss=4.2806\n","Epoch 10, Loss=2.3769\n","Epoch 20, Loss=2.3725\n","Epoch 30, Loss=2.5510\n","Epoch 40, Loss=2.5296\n","Epoch 50, Loss=2.4130\n","Epoch 60, Loss=2.4343\n","Epoch 70, Loss=2.5680\n","Epoch 80, Loss=2.5284\n","Epoch 90, Loss=2.4141\n","\n","Predictions:\n","Doc: 'The hockey puck hit the goal' => {'rec.sport.hockey': np.float64(0.836), 'sci.electronics': np.float64(0.164)}\n","Doc: 'The voltage in the circuit is high' => {'rec.sport.hockey': np.float64(0.281), 'sci.electronics': np.float64(0.719)}\n"]}]}]}