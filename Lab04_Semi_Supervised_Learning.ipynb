{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owYX7wuzvQ0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffda025d-dd94-491a-e87f-19fe67f80671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i=  2   Change of Lables=   0.20204603580562663\n",
            "i=  3   Change of Lables=   0.1601023017902813\n",
            "i=  4   Change of Lables=   0.16982097186700762\n",
            "i=  5   Change of Lables=   0.09462915601023014\n",
            "i=  6   Change of Lables=   0.051150895140664954\n",
            "i=  7   Change of Lables=   0.03631713554987215\n",
            "i=  8   Change of Lables=   0.03171355498721229\n",
            "i=  9   Change of Lables=   0.02250639386189257\n",
            "i=  10   Change of Lables=   0.017391304347826098\n",
            "i=  11   Change of Lables=   0.010741687979539671\n",
            "i=  12   Change of Lables=   0.009718670076726332\n",
            "i=  13   Change of Lables=   0.010230179028132946\n",
            "i=  14   Change of Lables=   0.013299232736572852\n",
            "i=  15   Change of Lables=   0.013299232736572852\n",
            "i=  16   Change of Lables=   0.013810741687979577\n",
            "i=  17   Change of Lables=   0.0117647058823529\n",
            "i=  18   Change of Lables=   0.010741687979539671\n",
            "i=  19   Change of Lables=   0.012787723785166238\n",
            "i=  20   Change of Lables=   0.016879795396419484\n",
            "i=  21   Change of Lables=   0.014833759590792805\n",
            "i=  22   Change of Lables=   0.014833759590792805\n",
            "i=  23   Change of Lables=   0.02148337595907923\n",
            "i=  24   Change of Lables=   0.01994884910485939\n",
            "i=  25   Change of Lables=   0.01790281329923271\n",
            "i=  26   Change of Lables=   0.005115089514066473\n",
            "i=  27   Change of Lables=   0.006138107416879812\n",
            "i=  28   Change of Lables=   0.003069053708439906\n",
            "i=  29   Change of Lables=   0.0\n",
            "\n",
            "Testing:\n",
            "\n",
            "Accuracy on the test data:  0.6448275862068965\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classes = ['sci.med', 'rec.motorcycles', 'talk.politics.guns']\n",
        "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, categories=classes)\n",
        "\n",
        "def extract_body(text):\n",
        "    # Split on first empty line (headers end)\n",
        "    parts = re.split(r'\\n\\s*\\n', text, maxsplit=1)\n",
        "    return parts[1] if len(parts) > 1 else text  # Return body only\n",
        "\n",
        "# Apply to all documents\n",
        "cleaned_data = [extract_body(doc) for doc in newsgroups.data]\n",
        "labels = newsgroups.target\n",
        "\n",
        "# spliting test and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(cleaned_data, labels, test_size=0.1)\n",
        "\n",
        "# splitting training data to labled and unlabled\n",
        "X_train_labled, X_train_unlabled, y_train_labled, dummy = train_test_split(X_train, y_train, test_size=0.75)\n",
        "\n",
        "# Create a CountVectorizer (BoW model)\n",
        "count_vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "\n",
        "# Fit and transform the labled training data\n",
        "X_train_labled = count_vectorizer.fit_transform(X_train_labled)\n",
        "\n",
        "# Fit and transform the labled training data\n",
        "X_train_unlabled = count_vectorizer.fit_transform(X_train_unlabled)\n",
        "\n",
        "# Transform the test data\n",
        "X_test = count_vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "#Training Starts...\n",
        "#model = LogisticRegression(max_iter=1000)\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_labled, y_train_labled) #model 0\n",
        "\n",
        "for i in range(1,100):\n",
        "  y_train_unlabled = model.predict(X_train_unlabled)\n",
        "  #print('Accuracy on the unlabled prediction: ',accuracy_score(dummy, y_train_unlabled))\n",
        "  if(i>1):\n",
        "    print('i= ',i,'  Change of Lables=  ',1-accuracy_score(y_train_unlabled, y_train_unlabled_previous))\n",
        "    if(accuracy_score(y_train_unlabled, y_train_unlabled_previous)>0.99999):\n",
        "      break\n",
        "  y_train_unlabled_previous = y_train_unlabled\n",
        "  X_combined = np.vstack([X_train_labled.toarray(), X_train_unlabled.toarray()])\n",
        "  y_combined = np.concatenate([y_train_labled, y_train_unlabled])\n",
        "\n",
        "  # Retrain the model on the combined data\n",
        "  model.fit(X_combined, y_combined)  #i th model\n",
        "\n",
        "#testing\n",
        "print('\\nTesting:\\n')\n",
        "print('Accuracy on the test data: ',accuracy_score(y_test, model.predict(X_test)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d5HDCYA93ADp"
      }
    }
  ]
}